{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "454bf0c7-4e17-6d71-0b4d-e67cf1bff734"
   },
   "source": [
    "https://www.kaggle.com/rickymos/basic-machine-learning-with-cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "e3200e6e-62d4-1d74-496b-c5197a574dcb"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd  \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns # used for plot interactive graph\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.model_selection import train_test_split \n",
    "# from sklearn.cross_validation import KFold # use for cross validation #deprecated\n",
    "from sklearn.model_selection import GridSearchCV# for tuning parameter\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm \n",
    "from sklearn import metrics \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_cell_guid": "68f07b98-c05a-f3e6-7dbe-8e39ab7d13f6"
   },
   "outputs": [],
   "source": [
    "# Separate mean, std, worst columns\n",
    "features_mean = df.loc[:, df.columns.str.contains('_mean')]\n",
    "features_se = df.loc[:, df.columns.str.contains('_se')]\n",
    "features_worst = df.loc[:, df.columns.str.contains('_worst')]\n",
    "\n",
    "# print(list(features_mean))\n",
    "# print(len(features_mean.columns))\n",
    "# print('-' * 100)\n",
    "# print(list(features_se))\n",
    "# print(len(features_se.columns))\n",
    "# print('-' * 100)\n",
    "# print(list(features_worst))\n",
    "# print(len(features_worst.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "dbdd0bf6-da03-c390-0e7a-f6b181f8e127"
   },
   "outputs": [],
   "source": [
    "# to do\n",
    "data['diagnosis']=data['diagnosis'].map({'M':1,'B':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_cell_guid": "598dce8d-1245-14e5-0e1c-ab609e51fec6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessie/opt/anaconda3/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# maglinant vs benign cases\n",
    "sns.countplot(df['diagnosis'],label=\"Count\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_mean  perimeter_mean  area_mean\n",
       "0          17.99          122.80     1001.0\n",
       "1          20.57          132.90     1326.0\n",
       "2          19.69          130.00     1203.0\n",
       "3          11.42           77.58      386.1\n",
       "4          20.29          135.10     1297.0\n",
       "..           ...             ...        ...\n",
       "564        21.56          142.00     1479.0\n",
       "565        20.13          131.20     1261.0\n",
       "566        16.60          108.30      858.1\n",
       "567        20.60          140.10     1265.0\n",
       "568         7.76           47.92      181.0\n",
       "\n",
       "[569 rows x 3 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_mean[['radius_mean', 'perimeter_mean', 'area_mean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "_cell_guid": "f9ee0ccd-4364-6186-e844-87ed319c1519"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   fractal_dimension_mean  \n",
       "0                 0.07871  \n",
       "1                 0.05667  \n",
       "2                 0.05999  \n",
       "3                 0.09744  \n",
       "4                 0.05883  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = features_mean\n",
    "y = df.diagnosis \n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "fcd92fe8-fb89-d377-f135-c053e562e820"
   },
   "outputs": [],
   "source": [
    "prediction_var = ['texture_mean','perimeter_mean','smoothness_mean','compactness_mean','symmetry_mean']\n",
    "# now these are the variables which will use for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "da2eaf5c-6f86-b320-a591-fb7b7e0fb12c"
   },
   "outputs": [],
   "source": [
    "#now split our data into train and test\n",
    "train, test = train_test_split(data, test_size = 0.3)# in this our main data is splitted into train and test\n",
    "# we can check their dimension\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "27cb4563-3191-8ab9-8ce2-224c2db223d0"
   },
   "outputs": [],
   "source": [
    "train_X = train[prediction_var]# taking the training data input \n",
    "train_y=train.diagnosis# This is output of our training data\n",
    "# same we have to do for test\n",
    "test_X= test[prediction_var] # taking test data inputs\n",
    "test_y =test.diagnosis   #output value of test dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4936a3a9-e7fd-81a1-1aec-a267224569d5"
   },
   "outputs": [],
   "source": [
    "model=RandomForestClassifier(n_estimators=100)# a simple random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c20ee887-14c4-fd6c-98fe-d54c06d6d4e4"
   },
   "outputs": [],
   "source": [
    "model.fit(train_X,train_y)# now fit our model for traiing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "abb767bd-ed3e-6af0-9aa5-55ccbf50f9c7"
   },
   "outputs": [],
   "source": [
    "prediction=model.predict(test_X)# predict for the test data\n",
    "# prediction will contain the predicted value by our model predicted values of dignosis column for test inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f37e4a4e-214c-9f56-391b-19a9a6b141ec"
   },
   "outputs": [],
   "source": [
    "metrics.accuracy_score(prediction,test_y) # to check the accuracy\n",
    "# here we will use accuracy measurement between our predicted value and our test output values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b8ae477d-f309-03b1-e224-f993ee9fed5b"
   },
   "source": [
    "* Here the Accuracy for our model is 91 % which seems good*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f1340630-a7e2-2f63-5b53-0fb407f5e177"
   },
   "outputs": [],
   "source": [
    "# lets now try with SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "74acfdf3-a6c1-e262-eaf5-742c62bf1382"
   },
   "outputs": [],
   "source": [
    "model = svm.SVC()\n",
    "model.fit(train_X,train_y)\n",
    "prediction=model.predict(test_X)\n",
    "metrics.accuracy_score(prediction,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3a2a515c-5b1f-4086-48cb-96dbaa67815c"
   },
   "source": [
    "**SVM is giving only 0.85 which we can improve by using different techniques** \n",
    "**i will improve it till then beginners can understand how to model a data and they can have a overview of ML**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "87950903-844c-058d-23d5-2d55ae58de75"
   },
   "source": [
    "*Now lets do this for all feature_mean so that from Random forest we can get the feature which are important**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4dd23ad4-a0e5-09e3-4319-187051f24199"
   },
   "outputs": [],
   "source": [
    "prediction_var = features_mean # taking all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8ffa199c-9f4e-8574-430d-d3133ae0d8c6"
   },
   "outputs": [],
   "source": [
    "train_X= train[prediction_var]\n",
    "train_y= train.diagnosis\n",
    "test_X = test[prediction_var]\n",
    "test_y = test.diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "20b8aaf5-677c-a2af-c998-dfd5fa713115"
   },
   "outputs": [],
   "source": [
    "model=RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b55cdfda-aab0-4130-990f-506754f16734"
   },
   "outputs": [],
   "source": [
    "model.fit(train_X,train_y)\n",
    "prediction = model.predict(test_X)\n",
    "metrics.accuracy_score(prediction,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8d0c1af5-f907-00c5-e189-3dc1e78c032b"
   },
   "source": [
    " - by taking all features accuracy increased but not so much so according to Razor's rule simpler method is better\n",
    " - by the way now lets check the importan features in the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "de3e85a8-20c3-8ebf-57f0-68dd360e0816"
   },
   "outputs": [],
   "source": [
    "featimp = pd.Series(model.feature_importances_, index=prediction_var).sort_values(ascending=False)\n",
    "print(featimp) # this is the property of Random Forest classifier that it provide us the importance \n",
    "# of the features used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b8a4c22d-757e-2768-b975-88656f0a9ad4"
   },
   "outputs": [],
   "source": [
    "# first lets do with SVM also using all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c0ae8f9c-05a7-e4b4-c7ac-4ca46c69c66e"
   },
   "outputs": [],
   "source": [
    "model = svm.SVC()\n",
    "model.fit(train_X,train_y)\n",
    "prediction=model.predict(test_X)\n",
    "metrics.accuracy_score(prediction,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6b8ba417-d74b-67fe-f507-6c648de683ed"
   },
   "outputs": [],
   "source": [
    "# as you can see the accuracy of SVM decrease very much\n",
    "# now lets take only top 5 important features given by RandomForest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "36a11667-fce7-4fa0-8b84-7780230ef339"
   },
   "outputs": [],
   "source": [
    "prediction_var=['concave points_mean','perimeter_mean' , 'concavity_mean' , 'radius_mean','area_mean']      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f9aafdb3-1ee7-56d7-57d0-ac009f9a9522"
   },
   "outputs": [],
   "source": [
    "train_X= train[prediction_var]\n",
    "train_y= train.diagnosis\n",
    "test_X = test[prediction_var]\n",
    "test_y = test.diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "37caf223-82ef-0579-32c8-de2a530faa3a"
   },
   "outputs": [],
   "source": [
    "model=RandomForestClassifier(n_estimators=100)\n",
    "model.fit(train_X,train_y)\n",
    "prediction = model.predict(test_X)\n",
    "metrics.accuracy_score(prediction,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "113982ab-8065-3e27-92b8-0716924138e7"
   },
   "outputs": [],
   "source": [
    "model = svm.SVC()\n",
    "model.fit(train_X,train_y)\n",
    "prediction=model.predict(test_X)\n",
    "metrics.accuracy_score(prediction,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "85893f2f-c831-e819-6724-f107ebf2833d"
   },
   "outputs": [],
   "source": [
    "# so from this discussion we got multi colinearty effecting our SVM part a lot \n",
    "# but its not affecting so much randomforest because for random forest we dont need to make so much effort for our analysis part\n",
    "# now lets do with the 3rd part of data which is worst\n",
    "# first start with all features_worst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "33c5c58a-31af-6309-1c6c-dd2280c0b112"
   },
   "outputs": [],
   "source": [
    "prediction_var = features_worst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e5a92132-7ec3-8901-e52e-b42973ae34f6"
   },
   "outputs": [],
   "source": [
    "train_X= train[prediction_var]\n",
    "train_y= train.diagnosis\n",
    "test_X = test[prediction_var]\n",
    "test_y = test.diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3f2fb8a5-176f-588f-86b9-676b4d94493c"
   },
   "outputs": [],
   "source": [
    "model = svm.SVC()\n",
    "model.fit(train_X,train_y)\n",
    "prediction=model.predict(test_X)\n",
    "metrics.accuracy_score(prediction,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1e0aa84e-24ea-496a-81ac-ddc145e2c3cd"
   },
   "outputs": [],
   "source": [
    "# but same problem With SVM, very much less accuray I think we have to tune its parameter\n",
    "# that i will do later in intermidate part\n",
    "#now we can get the important features from random forest now run Random Forest for it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "942c21fa-86f8-eb02-3dcc-e71c3bdaa1c6"
   },
   "outputs": [],
   "source": [
    "model=RandomForestClassifier(n_estimators=100)\n",
    "model.fit(train_X,train_y)\n",
    "prediction = model.predict(test_X)\n",
    "metrics.accuracy_score(prediction,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6fdbaa7b-2d17-d7df-91ac-d0b2d40ee29d"
   },
   "outputs": [],
   "source": [
    "# the accuracy for RandomForest invcrease it means the value are more catogrical in Worst part\n",
    "#lets get the important features\n",
    "featimp = pd.Series(model.feature_importances_, index=prediction_var).sort_values(ascending=False)\n",
    "print(featimp) # this is the property of Random Forest classifier that it provide us the importance \n",
    "# of the features used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b123094f-0ec6-a780-d247-e455e814b475"
   },
   "outputs": [],
   "source": [
    "# same parameter but with great importance and here it seamed the only conacve points_worst is making \n",
    "# very important so it may be bias lets check only for top 5 important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "152b0a6f-b34b-adc4-8c71-f9e46143e635"
   },
   "outputs": [],
   "source": [
    "prediction_var = ['concave points_worst','radius_worst','area_worst','perimeter_worst','concavity_worst'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c0157475-6e2b-0462-9898-5a443afb9d8c"
   },
   "outputs": [],
   "source": [
    "train_X= train[prediction_var]\n",
    "train_y= train.diagnosis\n",
    "test_X = test[prediction_var]\n",
    "test_y = test.diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0e9d0dcd-f06d-c281-1152-691a99754bc1"
   },
   "outputs": [],
   "source": [
    "model=RandomForestClassifier(n_estimators=100)\n",
    "model.fit(train_X,train_y)\n",
    "prediction = model.predict(test_X)\n",
    "metrics.accuracy_score(prediction,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b06553a2-25f9-ece8-00ef-cf139d887d04"
   },
   "outputs": [],
   "source": [
    "#check for SVM\n",
    "model = svm.SVC()\n",
    "model.fit(train_X,train_y)\n",
    "prediction=model.predict(test_X)\n",
    "metrics.accuracy_score(prediction,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "df8ac8b7-5ff4-ab3e-f1c2-f678af857730"
   },
   "outputs": [],
   "source": [
    "# now I think for simplicity the Randomforest will be better for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a701594e-ec58-29f2-079f-285a01c686b2"
   },
   "outputs": [],
   "source": [
    "# Now explore a little bit more\n",
    "# now from features_mean i will try to find the variable which can be use for classify\n",
    "# so lets plot a scatter plot for identify those variable who have a separable boundary between two class\n",
    "#of cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a10b6b41-e528-2eb0-5f22-086af611e4fe"
   },
   "outputs": [],
   "source": [
    "# Lets start with the data analysis for features_mean\n",
    "# Just try to understand which features can be used for prediction\n",
    "# I will plot scatter plot for the all features_mean for both of diagnosis Category\n",
    "# and from it we will find which are easily can used for differenciate between two category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "834d5543-115d-55f9-0289-5709ed068e7d"
   },
   "outputs": [],
   "source": [
    "color_function = {0: \"blue\", 1: \"red\"} # Here Red color will be 1 which means M and blue foo 0 means B\n",
    "colors = data[\"diagnosis\"].map(lambda x: color_function.get(x))# mapping the color fuction with diagnosis column\n",
    "pd.scatter_matrix(data[features_mean], c=colors, alpha = 0.5, figsize = (15, 15)); # plotting scatter plot matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "78883101-b683-4a38-efdf-961db36f673a"
   },
   "source": [
    "** Observation**\n",
    "\n",
    "** 1. Radius, area and perimeter have a strong linear relationship as expected\n",
    "     2 As graph shows the features like as texture_mean, smoothness_mean, symmetry_mean and fractal_dimension_mean can t be used for classify two category because both category are mixed there is no separable plane\n",
    "3. So we can remove them from our prediction_var**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7fb4459c-b7c2-8dda-ff20-29757ca229fe"
   },
   "outputs": [],
   "source": [
    "# So predicton features will be \n",
    "features_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8a799df8-71c3-590a-f05e-2bbb4e8afa99"
   },
   "outputs": [],
   "source": [
    "# So predicton features will be \n",
    "predictor_var = ['radius_mean','perimeter_mean','area_mean','compactness_mean','concave points_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "128449c4-c45b-edd5-1978-452f0577477d"
   },
   "outputs": [],
   "source": [
    "# Now with these variable we will try to explore a liitle bit we will move to how to use cross validiation\n",
    "# for a detail on cross validation use this link https://www.analyticsvidhya.com/blog/2015/11/improve-model-performance-cross-validation-in-python-r/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8ab6c00c-e045-3ed7-d8fa-cb59629ed18a"
   },
   "outputs": [],
   "source": [
    "def model(model,data,prediction,outcome):\n",
    "    # This function will be used for to check accuracy of different model\n",
    "    # model is the m\n",
    "    kf = KFold(data.shape[0], n_folds=10) # if you have refer the link then you must understand what is n_folds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "fa211445-a1b2-9521-3502-24d39562ddda"
   },
   "outputs": [],
   "source": [
    "prediction_var = ['radius_mean','perimeter_mean','area_mean','compactness_mean','concave points_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "58c24a07-d0c2-005d-2049-3b07af37d36b"
   },
   "outputs": [],
   "source": [
    "# so those features who are capable of classify classe will be more useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "44635f70-d0a3-c8b5-4b5e-6ad8be28a6b3"
   },
   "outputs": [],
   "source": [
    "# so in this part i am going to explain about only some concept of machine learnig \n",
    "# here I will also compare the accuracy of different models\n",
    "# I will First use cross validation with different model\n",
    "# then I will explain about how to to tune the parameter of models using gridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f8b5ac97-0cfc-32fb-9fda-81e6b01bac57"
   },
   "outputs": [],
   "source": [
    "# As we are going to use many models lets make a function\n",
    "# Which we can use with different models\n",
    "def classification_model(model,data,prediction_input,output):\n",
    "    # here the model means the model \n",
    "    # data is used for the data \n",
    "    #prediction_input means the inputs used for prediction\n",
    "    # output mean the value which are to be predicted\n",
    "    # here we will try to find out the Accuarcy of model by using same data for fiiting and \n",
    "    #comparison for same data\n",
    "    #Fit the model:\n",
    "    model.fit(data[prediction_input],data[output]) #Here we fit the model using training set\n",
    "  \n",
    "    #Make predictions on training set:\n",
    "    predictions = model.predict(data[prediction_input])\n",
    "  \n",
    "    #Print accuracy\n",
    "    # now checkin accuracy for same data\n",
    "    accuracy = metrics.accuracy_score(predictions,data[output])\n",
    "    print(\"Accuracy : %s\" % \"{0:.3%}\".format(accuracy))\n",
    " \n",
    "    \n",
    "    kf = KFold(data.shape[0], n_folds=5)\n",
    "    # About cross validitaion please follow this link\n",
    "    #https://www.analyticsvidhya.com/blog/2015/11/improve-model-performance-cross-validation-in-python-r/\n",
    "    #let me explain a little bit data.shape[0] means number of rows in data\n",
    "    #n_folds is for number of folds\n",
    "    error = []\n",
    "    for train, test in kf:\n",
    "        # as the data is divided into train and test using KFold\n",
    "        # now as explained above we have fit many models \n",
    "        # so here also we are going to fit model\n",
    "        #in the cross validation the data in train and test will change for evry iteration\n",
    "        train_X = (data[prediction_input].iloc[train,:])# in this iloc is used for index of trainig data\n",
    "        # here iloc[train,:] means all row in train in kf amd the all columns\n",
    "        train_y = data[output].iloc[train]# here is only column so it repersenting only row in train\n",
    "        # Training the algorithm using the predictors and target.\n",
    "        model.fit(train_X, train_y)\n",
    "    \n",
    "        # now do this for test data also\n",
    "        test_X=data[prediction_input].iloc[test,:]\n",
    "        test_y=data[output].iloc[test]\n",
    "        error.append(model.score(test_X,test_y))\n",
    "        # printing the score \n",
    "        print(\"Cross-Validation Score : %s\" % \"{0:.3%}\".format(np.mean(error)))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4b9362b9-2514-685f-6830-d390cf729ac8"
   },
   "outputs": [],
   "source": [
    "# Now from Here start using different model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a989f695-6939-743c-c3dd-6f6203ad7f02"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f8038059-da27-77a5-a67a-2a3936149919"
   },
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "prediction_var = ['radius_mean','perimeter_mean','area_mean','compactness_mean','concave points_mean']\n",
    "outcome_var= \"diagnosis\"\n",
    "classification_model(model,data,prediction_var,outcome_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2e6a3fcb-7001-a7f3-c662-325706f59db6"
   },
   "source": [
    "**observation\n",
    "\n",
    " 1. Accuracy is 100 % means over fitting \n",
    " 2. but cross validation scores are not good\n",
    " 3 so accuracy cant be considered only factor here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ff54139d-7f93-6180-d3cf-ca8f6a9c1c2f"
   },
   "outputs": [],
   "source": [
    "# now move to svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "95e14b94-d970-318a-c94f-89bb8d253d78"
   },
   "outputs": [],
   "source": [
    "model = svm.SVC()\n",
    "\n",
    "classification_model(model,data,prediction_var,outcome_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "61fb1252-dfd0-6cc5-7085-af14ea1acb58"
   },
   "outputs": [],
   "source": [
    "# I am facing problem with SVM dont know why?\n",
    "#lets leave that we will try to do it later "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "593073d9-7f25-06f4-2887-c937e0212da8"
   },
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier()\n",
    "classification_model(model,data,prediction_var,outcome_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a0bc621f-8cd3-62aa-0058-79cad0313e94"
   },
   "outputs": [],
   "source": [
    "# same here cross validation scores are not good\n",
    "# now move to RandomForestclassifier\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "classification_model(model,data,prediction_var,outcome_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "be1ef210-09d6-1e8e-1972-4b7b7efda883"
   },
   "outputs": [],
   "source": [
    "# cross validation score are also not bed\n",
    "# so Random forest is good\n",
    "# lets try with logistic regression\n",
    "model=LogisticRegression()\n",
    "classification_model(model,data,prediction_var,outcome_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "42918503-55a6-b2ac-256a-81b8adfd67ad"
   },
   "source": [
    "** It was a detailed comparison of machine learning models \n",
    "\n",
    " 1. In next segment I will try to  explain the tuning of parameter for different models\n",
    " 2. Then using those parameter we will try to forecast**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a67b38c7-d64d-04e1-7d29-ec2476102e41"
   },
   "source": [
    "** Tuning Parameters  using grid search CV**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ed127fda-4f0b-5e94-9a9e-c5e56701050b"
   },
   "source": [
    " *Lets Start with decision tree classifier\n",
    "Tuning the parameters means using the best parameter for predict \n",
    " there are many parameters need to model a Machine learning Algorithm\n",
    " for decision tree classifier refer this link [Link](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c9a0f2cf-8ac9-e434-d300-54f898f74d04"
   },
   "outputs": [],
   "source": [
    "data_X= data[prediction_var]\n",
    "data_y= data[\"diagnosis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e2f69f37-7dcd-7afe-1307-b0b16af59c2a"
   },
   "outputs": [],
   "source": [
    "# lets Make a function for Grid Search CV\n",
    "def Classification_model_gridsearchCV(model,param_grid,data_X,data_y):\n",
    "    clf = GridSearchCV(model,param_grid,cv=10,scoring=\"accuracy\")\n",
    "    # this is how we use grid serch CV we are giving our model\n",
    "    # the we gave parameters those we want to tune\n",
    "    # Cv is for cross validation\n",
    "    # scoring means to score the classifier\n",
    "    \n",
    "    clf.fit(train_X,train_y)\n",
    "    print(\"The best parameter found on development set is :\")\n",
    "    # this will gie us our best parameter to use\n",
    "    print(clf.best_params_)\n",
    "    print(\"the bset estimator is \")\n",
    "    print(clf.best_estimator_)\n",
    "    print(\"The best score is \")\n",
    "    # this is the best score that we can achieve using these parameters#\n",
    "    print(clf.best_score_)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "fff56e83-608f-bee1-8cdf-d75b07cab36a"
   },
   "outputs": [],
   "source": [
    "# Here we have to take parameters that are used for Decison tree Classifier\n",
    "# you will understand these terms once you follow the link above\n",
    "param_grid = {'max_features': ['auto', 'sqrt', 'log2'],\n",
    "              'min_samples_split': [2,3,4,5,6,7,8,9,10], \n",
    "              'min_samples_leaf':[2,3,4,5,6,7,8,9,10] }\n",
    "# here our gridasearchCV will take all combinations of these parameter and apply it to model \n",
    "# and then it will find the best parameter for model\n",
    "model= DecisionTreeClassifier()\n",
    "Classification_model_gridsearchCV(model,param_grid,data_X,data_y)\n",
    "# call our function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "67fb10fa-b386-2c7c-6c3c-d23119ab0501"
   },
   "source": [
    "*observation*\n",
    "\n",
    " 1. the score increase to 95 % \n",
    " 2. Seems to be good\n",
    " 3. Lets do with KNN\n",
    " 4. link for KNN  [Link](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)\n",
    " 5. if you are a beginner please follow the link it will be very much useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f5238051-7292-5a2a-f255-cd68c9797125"
   },
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier()\n",
    "\n",
    "k_range = list(range(1, 30))\n",
    "leaf_size = list(range(1,30))\n",
    "weight_options = ['uniform', 'distance']\n",
    "param_grid = {'n_neighbors': k_range, 'leaf_size': leaf_size, 'weights': weight_options}\n",
    "Classification_model_gridsearchCV(model,param_grid,data_X,data_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d7918a00-0d11-f883-98a5-cab998584c03"
   },
   "source": [
    " 1. Try with SVM\n",
    " 2. [link](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0c2e19e8-bd5f-45d3-3134-845c0c4ad11f"
   },
   "outputs": [],
   "source": [
    "model=svm.SVC()\n",
    "param_grid = [\n",
    "              {'C': [1, 10, 100, 1000], \n",
    "               'kernel': ['linear']\n",
    "              },\n",
    "              {'C': [1, 10, 100, 1000], \n",
    "               'gamma': [0.001, 0.0001], \n",
    "               'kernel': ['rbf']\n",
    "              },\n",
    " ]\n",
    "Classification_model_gridsearchCV(model,param_grid,data_X,data_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a3e8c0c9-1a3a-047e-0fa3-bdfff182caaa"
   },
   "source": [
    "*observation*\n",
    "\n",
    " 1. The SVM is working fine with good parameter it shows us what is the use of running of parameters\n",
    " 2. In the first by using default  I was getting only 70 % accuracy\n",
    " 3. But with tuned parameter it is 95 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e1b37871-b764-9553-b059-108aa553d43b"
   },
   "source": [
    " 1. Same we can do for Random Forest classifier\n",
    " 2. I will not do that \n",
    " 3. if someone is using this as reference please do for Random Forest Classifier also"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bc71536e-4f9f-0f5c-9363-3f27b643235f"
   },
   "source": [
    " 1. The main objective of this notebook is to provide a hang on the the Machine learning methods\n",
    " 2. I think it will be very useful for beginner because in this I have provided every thing that a beginner needs  most\n",
    " 3. When I  was a beginner I face many problems finding these all so i tried to make everything available here \n",
    " 4. Thanks "
   ]
  }
 ],
 "metadata": {
  "_change_revision": 0,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
